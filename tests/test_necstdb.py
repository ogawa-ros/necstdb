import pathlib
import struct

import pytest
import numpy
import pandas

import necstdb

TIME = 1630042892.423945

DATA1_HEADER = {
    "data": [
        {"key": "test_bool", "format": "?", "size": 1},
        {"key": "test_int8", "format": "b", "size": 1},
        {"key": "test_int16", "format": "h", "size": 2},
        {"key": "test_int32", "format": "i", "size": 4},
        {"key": "test_int64", "format": "q", "size": 8},
    ],
    "memo": "generated by test_necstdb",
    "necstdb_version": necstdb.__version__,
}
DATA2_HEADER = {
    "data": [
        {"key": "test_uint8", "format": "B", "size": 1},
        {"key": "test_uint16", "format": "H", "size": 2},
        {"key": "test_uint32", "format": "I", "size": 4},
        {"key": "test_uint64", "format": "Q", "size": 8},
        {"key": "test_string", "format": "6s", "size": 6},
    ],
    "memo": "generated by test_necstdb",
    "necstdb_version": necstdb.__version__,
}
DATA3_HEADER = {
    "data": [
        {"key": "test_float32", "format": "f", "size": 4},
        {"key": "test_float64", "format": "d", "size": 8},
        # The following 2 formats have been supported by ROS but are now deprecated.
        {"key": "test__byte", "format": "5s", "size": 5},
        {"key": "test__char", "format": "c", "size": 1},
        # Array data.
        {"key": "test_array", "format": "3d", "size": 24},
    ],
    "memo": "generated by test_necstdb",
    "necstdb_version": necstdb.__version__,
}


def DATA1(length):
    for i in range(length):
        yield [True, i, -16, -32, -64]


def DATA2(length):
    for i in range(length):
        yield [i, 16, 32, 64, b"string"]


def DATA3(length):
    for i in range(length):
        yield [32.32, i, b"bytes", b"c", [TIME, TIME, TIME]]


# dtypes are not preserved
# array data are flattened
EXPECTED_DATA1_TUPLE = (True, 0, -16, -32, -64)
EXPECTED_DATA2_TUPLE = (0, 16, 32, 64, b"string")
EXPECTED_DATA3_TUPLE = pytest.approx((32.32, 0, b"bytes", b"c", TIME, TIME, TIME))

# dtypes are not preserved
EXPECTED_DATA1_DICT = {
    "test_bool": True,
    "test_int8": 0,
    "test_int16": -16,
    "test_int32": -32,
    "test_int64": -64,
}
EXPECTED_DATA2_DICT = {
    "test_uint8": 0,
    "test_uint16": 16,
    "test_uint32": 32,
    "test_uint64": 64,
    "test_string": b"string",
}
EXPECTED_DATA3_DICT = pytest.approx(
    {
        "test_float32": 32.32,
        "test_float64": 0,
        "test__byte": b"bytes",
        "test__char": b"c",
        "test_array": (TIME, TIME, TIME),
    }
)

# dtypes are not preserved
EXPECTED_DATA1_DF = pandas.DataFrame(
    [(True, 0, -16, -32, -64)],
    columns=["test_bool", "test_int8", "test_int16", "test_int32", "test_int64"],
)
EXPECTED_DATA2_DF = pandas.DataFrame(
    [(0, 16, 32, 64, b"string")],
    columns=["test_uint8", "test_uint16", "test_uint32", "test_uint64", "test_string"],
)
EXPECTED_DATA3_DF = pandas.DataFrame(
    [(32.32, 0, b"bytes", b"c", [TIME, TIME, TIME])],
    columns=["test_float32", "test_float64", "test__byte", "test__char", "test_array"],
)

EXPECTED_DATA1_ARRAY = numpy.array(
    [(True, 0, -16, -32, -64)],
    dtype=[
        ("test_bool", "?"),
        ("test_int8", "i1"),
        ("test_int16", "i2"),
        ("test_int32", "i4"),
        ("test_int64", "i8"),
    ],
)
EXPECTED_DATA2_ARRAY = numpy.array(
    [(0, 16, 32, 64, b"string")],
    dtype=[
        ("test_uint8", "u1"),
        ("test_uint16", "u2"),
        ("test_uint32", "u4"),
        ("test_uint64", "u8"),
        ("test_string", "S6"),
    ],
)
EXPECTED_DATA3_ARRAY = numpy.array(
    [(32.32, 0, b"bytes", b"c", [TIME, TIME, TIME])],
    dtype=[
        ("test_float32", "f4"),
        ("test_float64", "f8"),
        ("test__byte", "S5"),
        ("test__char", "S1"),
        ("test_array", "3f8"),
    ],
)

EXPECTED_DATA1_BUFFER = (
    b"\x01\x00\xf0\xff\xe0\xff\xff\xff\xc0\xff\xff\xff\xff\xff\xff\xff"
)
EXPECTED_DATA2_BUFFER = b"\x00\x10\x00 \x00\x00\x00@\x00\x00\x00\x00\x00\x00\x00string"
EXPECTED_DATA3_BUFFER = (
    b"\xaeG\x01B\x00\x00\x00\x00\x00\x00\x00\x00bytesc"
    b"\xea!\x1b\xc3\x1eJ\xd8A\xea!\x1b\xc3\x1eJ\xd8A\xea!\x1b\xc3\x1eJ\xd8A"
)


# The data order is not preserved.
EXPECTED_PARTIAL_DATA3_TUPLE = (b"bytes", TIME, TIME, TIME, b"c", 3)

EXPECTED_PARTIAL_DATA3_DICT = pytest.approx(
    {
        "test__byte": b"bytes",
        "test_array": (TIME, TIME, TIME),
        "test__char": b"c",
        "test_float64": 3,
    }
)
EXPECTED_PARTIAL_DATA3_DF = pandas.DataFrame(
    [(b"bytes", [TIME, TIME, TIME], b"c", 3)],
    columns=["test__byte", "test_array", "test__char", "test_float64"],
)
EXPECTED_PARTIAL_DATA3_ARRAY = numpy.array(
    [(b"bytes", [TIME, TIME, TIME], b"c", 3)],
    dtype=[
        ("test__byte", "S5"),
        ("test_array", "3f8"),
        ("test__char", "S1"),
        ("test_float64", "f8"),
    ],
)
EXPECTED_PARTIAL_DATA3_BUFFER = (
    b"bytes\xea!\x1b\xc3\x1eJ\xd8A\xea!\x1b\xc3\x1eJ\xd8A\xea!\x1b\xc3\x1eJ\xd8A"
    b"c\x00\x00\x00\x00\x00\x00\x08@"
)


@pytest.fixture(scope="module")
def tmp_db_path(tmp_path_factory) -> pathlib.Path:
    """Make variable 'tmp_db_path' available from throughout this test module."""
    return tmp_path_factory.mktemp("test_db")


@pytest.mark.usefixtures("tmp_db_path")
class TestWriteDatabase:
    def test_write_db(self, tmp_db_path):
        db = necstdb.opendb(tmp_db_path, mode="w")
        db.create_table("data1", DATA1_HEADER)
        db.create_table("data2", DATA2_HEADER)
        db.create_table("data3", DATA3_HEADER)
        table = {
            name: db.open_table(name, mode="ab") for name in ["data1", "data2", "data3"]
        }
        for data in DATA1(19):
            table["data1"].append(*data)
        for data in DATA2(31):
            table["data2"].append(*data)
        for data in DATA3(43):
            data_ = []
            _ = [  # Flatten the data.
                data_.extend(dat) if isinstance(dat, list) else data_.append(dat)
                for dat in data
            ]
            table["data3"].append(*data_)
        _ = [tab.close() for tab in table.values()]


@pytest.fixture(scope="module")
def db_read(tmp_db_path) -> necstdb.necstdb:
    """Make variable 'db_read' available from throughout this test module."""
    return necstdb.opendb(tmp_db_path)


@pytest.mark.usefixtures("db_read")
class TestReadDatabase:
    def test_read_types(self, db_read):
        """Keys test."""
        tuple_key = ["tuple"]
        dict_key = ["dict"]
        df_key = ["pandas", "dataframe", "data_frame", "df"]
        array_key = ["structuredarray", "structured_array", "array", "sa"]
        buffer_key = ["buffer", "raw"]

        for type_ in tuple_key + dict_key + df_key + array_key + buffer_key:
            _ = db_read.open_table("data1").read(astype=type_)

    def test_read_tuple(self, db_read):
        """Read as tuple."""
        actual = {
            name: db_read.open_table(name).read(astype="tuple")
            for name in ["data1", "data2", "data3"]
        }

        assert len(actual["data1"]) == 19, "[tuple] Data number error."
        assert EXPECTED_DATA1_TUPLE == actual["data1"][0], "[tuple] Data error."
        assert EXPECTED_DATA2_TUPLE == actual["data2"][0], "[tuple] Data error."
        assert EXPECTED_DATA3_TUPLE == actual["data3"][0], "[tuple] Data error."
        with pytest.raises(TypeError):
            # Array data are not supported for tuple.
            assert len(actual["data3"][0][-1]) == 3, "[tuple] Array handling error."

    def test_read_dict(self, db_read):
        """Read as dict."""
        actual = {
            name: db_read.open_table(name).read(astype="dict")
            for name in ["data1", "data2", "data3"]
        }

        assert len(actual["data1"]) == 19, "[dict] Data number error."
        assert EXPECTED_DATA1_DICT == actual["data1"][0], "[dict] Data error."
        assert EXPECTED_DATA2_DICT == actual["data2"][0], "[dict] Data error."
        assert EXPECTED_DATA3_DICT == actual["data3"][0], "[dict] Data error."
        err_msg = "[dict] Array handling error."
        assert len(actual["data3"][0]["test_array"]) == 3, err_msg

    def test_read_df(self, db_read):
        """Read as pandas.DataFrame."""
        actual = {
            name: db_read.open_table(name).read(astype="pandas")
            for name in ["data1", "data2", "data3"]
        }

        assert len(actual["data1"]) == 19, "[pandas] Data number error."
        assert all(EXPECTED_DATA1_DF == actual["data1"].loc[0]), "[pandas] Data error."
        assert all(EXPECTED_DATA2_DF == actual["data2"].loc[0]), "[pandas] Data error."
        assert all(EXPECTED_DATA3_DF == actual["data3"].loc[0]), "[pandas] Data error."
        err_msg = "[pandas] Array handling error."
        assert len(actual["data3"].loc[0, "test_array"]) == 3, err_msg

    def test_read_array(self, db_read):
        """Read as numpy.ndarray."""
        actual = {
            name: db_read.open_table(name).read(astype="array")
            for name in ["data1", "data2", "data3"]
        }

        assert len(actual["data1"]) == 19, "[array] Data number error."
        assert all(EXPECTED_DATA1_ARRAY == actual["data1"][0]), "[array] Data error."
        assert all(EXPECTED_DATA2_ARRAY == actual["data2"][0]), "[array] Data error."
        assert all(EXPECTED_DATA3_ARRAY == actual["data3"][0]), "[array] Data error."
        err_msg = "[array] Array handling error."
        assert len(actual["data3"][0]["test_array"]) == 3, err_msg

    def test_read_buffer(self, db_read):
        """Read raw data."""
        actual = {
            name: db_read.open_table(name).read(astype="buffer")
            for name in ["data1", "data2", "data3"]
        }
        unpacked = {
            k: tuple(struct.iter_unpack(fmt, v))
            for fmt, (k, v) in zip(["<?bhiq", "<BHIQ6s", "<fd5sc3d"], actual.items())
        }
        size = {
            k: struct.calcsize(fmt)
            for k, fmt in zip(actual.keys(), ["<?bhiq", "<BHIQ6s", "<fd5sc3d"])
        }

        assert len(unpacked["data1"]) == 19, "[buffer] Data number error."
        err_msg = "[buffer] Data error."
        assert EXPECTED_DATA1_BUFFER == actual["data1"][: size["data1"]], err_msg
        assert EXPECTED_DATA2_BUFFER == actual["data2"][: size["data2"]], err_msg
        assert EXPECTED_DATA3_BUFFER == actual["data3"][: size["data3"]], err_msg
        with pytest.raises(TypeError):
            # Array data cannot be supported.
            assert len(unpacked["data3"][0][-1]) == 3, "[buffer] Array handling error."


@pytest.mark.usefixtures("db_read")
class TestPartialRead:
    def test_partial_read_tuple(self, db_read):
        actual = db_read.open_table("data3").read(
            astype="tuple",
            start=3,
            num=5,
            cols=["test__byte", "test_array", "test__char", "test_float64"],
        )

        assert len(actual) == 5, "[tuple] Length doesn't match."
        with pytest.raises(AssertionError):
            # Array data are not supported for tuple.
            assert len(actual[0]) == 4, "[tuple] Length doesn't match."
        err_msg = "[tuple] Start index error."
        with pytest.raises(AssertionError):
            # Data order is not preserved.
            assert actual[0] == EXPECTED_PARTIAL_DATA3_TUPLE, err_msg
        # Insensitive to the order.
        assert all(val in EXPECTED_PARTIAL_DATA3_TUPLE for val in actual[0]), err_msg

    def test_partial_read_dict(self, db_read):
        actual = db_read.open_table("data3").read(
            astype="dict",
            start=3,
            num=5,
            cols=["test__byte", "test_array", "test__char", "test_float64"],
        )

        assert len(actual) == 5, "[dict] Length doesn't match."
        assert len(actual[0]) == 4, "[dict] Length doesn't match."
        assert actual[0] == EXPECTED_PARTIAL_DATA3_DICT, "[dict] Start index error."

    def test_partial_read_df(self, db_read):
        actual = db_read.open_table("data3").read(
            astype="pandas",
            start=3,
            num=5,
            cols=["test__byte", "test_array", "test__char", "test_float64"],
        )

        assert len(actual) == 5, "[pandas] Length doesn't match."
        assert len(actual.loc[0]) == 4, "[pandas] Length doesn't match."
        err_msg = "[pandas] Start index error."
        assert all(actual.loc[0] == EXPECTED_PARTIAL_DATA3_DF), err_msg

    def test_partial_read_array(self, db_read):
        actual = db_read.open_table("data3").read(
            astype="array",
            start=3,
            num=5,
            cols=["test__byte", "test_array", "test__char", "test_float64"],
        )

        assert len(actual) == 5, "[array] Length doesn't match."
        assert len(actual[0]) == 4, "[array] Length doesn't match."
        err_msg = "[array] Start index error."
        assert all(actual[0] == EXPECTED_PARTIAL_DATA3_ARRAY), err_msg

    def test_partial_read_buffer(self, db_read):
        actual = db_read.open_table("data3").read(
            astype="buffer",
            start=3,
            num=5,
            cols=["test__byte", "test_array", "test__char", "test_float64"],
        )
        unpacked = tuple(struct.iter_unpack("<5s3dcd", actual))
        size = struct.calcsize("<5s3dcd")

        assert len(actual) == size * 5, "[buffer] Length doesn't match."
        with pytest.raises(AssertionError):
            # Array data are not supported for tuple.
            assert len(unpacked[0]) == 4, "[buffer] Length doesn't match."
        err_msg = "[buffer] Start index error."
        with pytest.raises(AssertionError):
            # Data order is not preserved.
            assert actual[:size] == EXPECTED_PARTIAL_DATA3_BUFFER, err_msg
        assert set(actual[:size]) == set(EXPECTED_PARTIAL_DATA3_BUFFER), err_msg


@pytest.fixture(scope="module")
def tmp_archive_path(tmp_path_factory) -> pathlib.Path:
    """Make variable 'tmp_archive_path' available from throughout this test module."""
    return tmp_path_factory.mktemp("archive")


@pytest.mark.usefixtures("db_read", "tmp_archive_path")
class TestFunction:
    def test_list_tables(self, db_read):
        err_msg = "Table name not correctly listed."
        assert db_read.list_tables() == ["data1", "data2", "data3"], err_msg

    def test_checkout(self, tmp_archive_path, db_read):
        save_path = tmp_archive_path / "archive.tar.gz"
        db_read.checkout(saveto=save_path, compression="gz")

        err_msg = "Archive file not correctly created."
        assert save_path.exists(), err_msg

    def test_get_info(self, db_read):
        actual = db_read.get_info()
        expected = pandas.DataFrame(
            [
                ("data1", 304, 19, 16, "<?bhiq"),
                ("data2", 651, 31, 21, "<BHIQ6s"),
                ("data3", 1806, 43, 42, "<fd5sc3d"),
            ],
            columns=[
                "table name",
                "file size [byte]",
                "#records",
                "record size [byte]",
                "format",
            ],
        ).set_index("table name")

        err_msg = "Information not correct."
        assert all(actual.index == expected.index), err_msg
        assert all(actual["#records"] == expected["#records"]), err_msg
        rec_size_key = "record size [byte]"
        assert all(actual[rec_size_key] == expected[rec_size_key]), err_msg
        assert all(actual["format"] == expected["format"]), err_msg
